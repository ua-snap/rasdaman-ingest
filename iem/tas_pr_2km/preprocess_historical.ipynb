{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb166f8-2518-4bce-a5bb-6a4dcbbe74f6",
   "metadata": {},
   "source": [
    "# CRU TS 4.0 Preprocessing\n",
    "\n",
    "Use this notebook to preprocess SNAP's 2km CRU TS 4.0 [temperature](http://ckan.snap.uaf.edu/dataset/historical-monthly-and-derived-temperature-products-downscaled-from-cru-ts-data-via-the-delta-m) and [precipitation](http://ckan.snap.uaf.edu/dataset/historical-monthly-and-derived-precipitation-products-downscaled-from-cru-ts-data-via-the-delta-m) data for ingest into rasdaman. The code in here is set up to compute average and standard deviation layers for each season for the period of 1950-2009 using the monthly means provided in the CRU TS 4.0 dataset (currently the only non-decadal dataset!). It then clips these new summary GeoTIFFs to the IEM extent.\n",
    "\n",
    "## Setup\n",
    "\n",
    "1. The CRU TS 4.0  GeoTIFFs need to be in a single folder for each variable, and each folder should be in the same directory. That directory may be stored in the `$SCRATCH_DIR` environment variable or may be set in the cell below. \n",
    "2. The shapefile for the IEM domain can be found in the [geospatial-vector-veractiy](https://github.com/ua-snap/geospatial-vector-veracity/blob/706c56855885165eab2c4817e8ca8a4ffb9d751a/vector_data/polygon/boundaries/iem/AIEM_domain.shp) repo. Clone this repo and change the input path as needed in the following code cell, or set the `$GVV_DIR` environment variable.\n",
    "\n",
    "Averaged and clipped rasters will be written to a single output folder with the name of the workding data directory plus the suffix `_1950-2009_<stat>_<season>_iem_domain`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a66987-89c3-409f-b8e4-8b4c30938a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# set paths to datasets and geospatial-vector-veractiy repo\n",
    "scratch_path = os.getenv(\"SCRATCH_DIR\") or \"/atlas_scratch/kmredilla/iem-webapp\"\n",
    "gvv_path = os.getenv(\"GVV_DIR\") or \"/workspace/UA/kmredilla/geospatial-vector-veracity\"\n",
    "\n",
    "scratch_dir = Path(scratch_path)\n",
    "gvv_dir = Path(gvv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbafc97-9d63-4bac-b1fc-8d460c626bae",
   "metadata": {},
   "source": [
    "## Get the extent of the clipped domain\n",
    "\n",
    "It is most efficient to only average over the extent of the IEM domain, since we will be clipping the final data to that polygon. Get the extent values from the domain shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61085d32-d34a-46d2-a17a-e7c8a1a8e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get extent of clipped raster using a sample FP\n",
    "# because we don't need to be averaging over areas\n",
    "# we don't intend to keep.\n",
    "\n",
    "# IEM domain\n",
    "# copied from /workspace/Shared/Tech_Projects/Alaska_IEM/project_data/IEM_Domain.zip\n",
    "aiem_domain_gdf = gpd.read_file(gvv_dir.joinpath(\"vector_data/polygon/boundaries/iem/AIEM_domain.shp\"))\n",
    "        \n",
    "bounds = {bound: value for bound, value in zip([\"wb\", \"sb\", \"eb\", \"nb\"], aiem_domain_gdf.bounds.values[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde4a2f8-9cd4-4263-bc91-7b6d393ed3ea",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "Use rasterio to do a windowed read of the rasters using the extent of the IEM domain. \n",
    "\n",
    "Set the `data_dir_name` variable below to be the name of the folder to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312258cd-7ed0-46cb-bc0a-62418ef7d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_name = \"cru_ts40_2km_monthly_tas\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5acb094-4846-46a6-83ec-68c4955a8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Window(col_off=717, row_off=84, width=1280, height=931)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rasterio as rio\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import Window\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# setup seasons to iterate over\n",
    "seasons = {\n",
    "    \"DJF\": [12, 1, 2],\n",
    "    \"MAM\": [3, 4, 5],\n",
    "    \"JJA\": [6, 7, 8],\n",
    "    \"SON\": [9, 10, 11],\n",
    "}\n",
    "\n",
    "# open a single file to get the row/column values for \n",
    "# windowed reading using the domain extent bounds\n",
    "fp = list(scratch_dir.joinpath(data_dir_name).glob(\"*.tif\")[0]\n",
    "with rio.open(fp) as src:\n",
    "    row_start = src.index(bounds[\"wb\"], bounds[\"nb\"])[0]\n",
    "    row_stop = src.index(bounds[\"wb\"], bounds[\"sb\"])[0]\n",
    "    col_start = src.index(bounds[\"wb\"], bounds[\"sb\"])[1]\n",
    "    col_stop = src.index(bounds[\"eb\"], bounds[\"sb\"])[1]\n",
    "    # also save metadata for later\n",
    "    meta = src.meta.copy()\n",
    "\n",
    "# create the window object for reuse\n",
    "window = Window.from_slices(slice(row_start, row_stop), slice(col_start, col_stop))\n",
    "\n",
    "# get the window tranform for the new new\n",
    "with rio.open(fp) as src:\n",
    "    win_transform = src.window_transform(window)\n",
    "\n",
    "\n",
    "\n",
    "def read_tif(args):\n",
    "    \"\"\"Read a geotiff using a window\"\"\"\n",
    "    fp, window = args\n",
    "    with rio.open(fp) as src:\n",
    "        return src.read(1, window=window)\n",
    "    \n",
    "\n",
    "def run_summary(fps, window):\n",
    "    \"\"\"Run the summarizaiton of the data files. Reads the data\n",
    "    into an array, and writes new files based on chosen summary\n",
    "    stat.\n",
    "    \"\"\"\n",
    "    arrs = []\n",
    "    args = [(fp, window) for fp in fps]\n",
    "    with Pool(32) as pool:\n",
    "        for out in tqdm(pool.imap(read_tif, args), total=len(args)):\n",
    "            arrs.append(out)\n",
    "    \n",
    "    arr = np.array(arrs)\n",
    "    \n",
    "    mean_arr = arr.mean(axis=0)\n",
    "    std_arr = arr.std(axis=0)\n",
    "    \n",
    "    return mean_arr, std_arr\n",
    "\n",
    "\n",
    "# def clip_raster():\n",
    "#     \"\"\"Clip a raster to clip_poly, crop to extent, \n",
    "#     and write to out_dir with same filename\n",
    "#     \"\"\"\n",
    "#     out_image, out_transform = mask(src, geoms, invert=True)\n",
    "    \n",
    "#     in_fp, clip_poly, bounds, out_dir = args\n",
    "#     with rio.open(in_fp) as src:\n",
    "#         arr, new_transform = mask(src, clip_poly)\n",
    "#         meta = src.meta.copy()\n",
    "#     arr = arr[0][bounds[\"nb\"]:bounds[\"sb\"], bounds[\"wb\"]:bounds[\"eb\"]]\n",
    "#     out_fp = out_dir.joinpath(in_fp.name.replace(\".tif\", \"_iem_domain.tif\"))\n",
    "#     meta[\"transform\"] = new_transform\n",
    "#     with rio.open(out_fp, \"w\", **meta) as dst:\n",
    "#         dst.write(arr, 1)\n",
    "        \n",
    "#     return out_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78ef2fd0-986a-43ad-8686-1af5f4b69c35",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "src_dir = scratch_dir.joinpath(data_dir_name)\n",
    "\n",
    "# iterate over seasons \n",
    "for season in seasons.keys():\n",
    "    months = seasons[season]\n",
    "    fps = []\n",
    "    for month in months:\n",
    "        fps.append(src_dir.glob(f\"*_{str(month).zfill(2)}_*.tif\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc34a5-01aa-4214-95ed-d0337e911bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4e2ab-f1bc-40e7-b05a-bb68cfd8e829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c5704-10a8-431b-9ebe-6584e9c77d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d565f9f-22ff-4d9b-ada7-30f650d52f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasdaman-ingest",
   "language": "python",
   "name": "rasdaman-ingest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
