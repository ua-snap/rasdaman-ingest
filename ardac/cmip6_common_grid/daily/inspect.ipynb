{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f7b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1919d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "timefix_dir = Path(\"/beegfs/CMIP6/jdpaul3/cmip6_regrid_timefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132b2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"pr\", \"tasmax\", \"tasmin\"]\n",
    "\n",
    "models_to_inspect = [\n",
    "    'CESM2',\n",
    "    'CNRM-CM6-1-HR',\n",
    "    'E3SM-2-0',\n",
    "    'EC-Earth3-Veg',\n",
    "    'GFDL-ESM4',\n",
    "    'HadGEM3-GC31-LL',\n",
    "    'HadGEM3-GC31-MM',\n",
    "    'KACE-1-0-G',\n",
    "    'MIROC6',\n",
    "    'MPI-ESM1-2-HR',\n",
    "    'MRI-ESM2-0',\n",
    "    'NorESM2-MM',\n",
    "    'TaiESM1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14fa3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(Path(timefix_dir).rglob(\"*day_*.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66a6c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using just the filenames, audit the files and create a table of the models, variables, scenarios, time range, and count of files\n",
    "# filename format: <variable>_day_<model>_<scenario>_regrid_<start_date>-<end_date>.nc\n",
    "# date format: YYYYMMDD\n",
    "data = []\n",
    "\n",
    "for file in files:\n",
    "    filename = file.name\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if len(parts) < 6:\n",
    "        continue  # skip files that do not match the expected format\n",
    "    \n",
    "    variable = parts[0]\n",
    "    model = parts[2]\n",
    "    scenario = parts[3]\n",
    "    start_date = parts[5].split('-')[0]  # YYYYMMDD\n",
    "    end_date = parts[5].split('-')[1].replace('.nc', '')  # YYYYMMDD\n",
    "    \n",
    "    if variable not in variables or model not in models_to_inspect:\n",
    "        continue  # skip files that are not of interest\n",
    "    \n",
    "    data.append({\n",
    "        'variable': variable,\n",
    "        'model': model,\n",
    "        'scenario': scenario,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'file_path': str(file)\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data)\n",
    "# Convert date strings to datetime objects for better handling\n",
    "df['start_date'] = pd.to_datetime(df['start_date'], format='%Y%m%d')\n",
    "df['end_date'] = pd.to_datetime(df['end_date'], format='%Y%m%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "957bea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check each row if any dates not start with jan 1 or end with december 31\n",
    "def check_date_range(row):\n",
    "    return row['start_date'].month == 1 and row['start_date'].day == 1 and \\\n",
    "           row['end_date'].month == 12 and row['end_date'].day == 31    \n",
    "\n",
    "# Apply the check to the DataFrame\n",
    "df['valid_date_range'] = df.apply(check_date_range, axis=1)\n",
    "# Filter the DataFrame to show only rows with invalid date ranges\n",
    "invalid_date_ranges = df[~df['valid_date_range']]\n",
    "# Print the DataFrame with invalid date ranges\n",
    "if not invalid_date_ranges.empty:\n",
    "    print(\"Files with invalid date ranges:\")\n",
    "    print(invalid_date_ranges[['variable', 'model', 'scenario', 'start_date', 'end_date', 'file_path']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24b87b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check each row if scenario = 'historical' and start_date != 19500101 or end_date != 20141231\n",
    "def check_historical_dates(row):\n",
    "    if row['scenario'] == 'historical':\n",
    "        return not (row['start_date'] == pd.Timestamp('1950-01-01') and \n",
    "                    row['end_date'] == pd.Timestamp('2014-12-31'))\n",
    "    return True  # For non-historical scenarios, we consider the dates valid\n",
    "# Apply the check to the DataFrame\n",
    "df['valid_historical_dates'] = df.apply(check_historical_dates, axis=1)\n",
    "# Filter the DataFrame to show only rows with invalid historical dates\n",
    "invalid_historical_dates = df[~df['valid_historical_dates']]\n",
    "# Print the DataFrame with invalid historical dates\n",
    "if not invalid_historical_dates.empty:\n",
    "    print(\"Files with invalid historical dates:\")\n",
    "    print(invalid_historical_dates[['variable', 'model', 'scenario', 'start_date', 'end_date', 'file_path']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa7be8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check each row if scenario != 'historical' and start_date != 20150101 or end_date != 21001231\n",
    "def check_future_dates(row):\n",
    "    if row['scenario'] != 'historical':\n",
    "        return not (row['start_date'] == pd.Timestamp('2015-01-01') and \n",
    "                    row['end_date'] == pd.Timestamp('2100-12-31'))\n",
    "    return True  # For historical scenarios, we consider the dates valid\n",
    "# Apply the check to the DataFrame\n",
    "df['valid_future_dates'] = df.apply(check_future_dates, axis=1)\n",
    "# Filter the DataFrame to show only rows with invalid future dates\n",
    "invalid_future_dates = df[~df['valid_future_dates']]\n",
    "# Print the DataFrame with invalid future dates\n",
    "if not invalid_future_dates.empty:\n",
    "    print(\"Files with invalid future dates:\")\n",
    "    print(invalid_future_dates[['variable', 'model', 'scenario', 'start_date', 'end_date', 'file_path']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72a01095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouped DataFrame by model, scenario, and variable:\n",
      "       model    scenario variable  count\n",
      "0      CESM2  historical       pr     65\n",
      "1      CESM2      ssp126       pr     86\n",
      "2      CESM2      ssp126   tasmax     86\n",
      "3      CESM2      ssp126   tasmin     86\n",
      "4      CESM2      ssp245       pr     86\n",
      "..       ...         ...      ...    ...\n",
      "164  TaiESM1      ssp370   tasmax     86\n",
      "165  TaiESM1      ssp370   tasmin     86\n",
      "166  TaiESM1      ssp585       pr     86\n",
      "167  TaiESM1      ssp585   tasmax     86\n",
      "168  TaiESM1      ssp585   tasmin     86\n",
      "\n",
      "[169 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# group by model and scenario, and list the variables and their counts\n",
    "grouped = df.groupby(['model', 'scenario', 'variable']).size().reset_index(name='count')\n",
    "# Print the grouped DataFrame\n",
    "print(\"\\nGrouped DataFrame by model, scenario, and variable:\")\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdecfb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>scenario</th>\n",
       "      <th>variable</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>EC-Earth3-Veg</td>\n",
       "      <td>ssp126</td>\n",
       "      <td>tasmax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EC-Earth3-Veg</td>\n",
       "      <td>ssp245</td>\n",
       "      <td>tasmax</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>EC-Earth3-Veg</td>\n",
       "      <td>ssp245</td>\n",
       "      <td>pr</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EC-Earth3-Veg</td>\n",
       "      <td>ssp245</td>\n",
       "      <td>tasmin</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>pr</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CESM2</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>tasmin</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CESM2</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>pr</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CESM2</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>tasmax</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CESM2</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>tasmin</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CNRM-CM6-1-HR</td>\n",
       "      <td>ssp126</td>\n",
       "      <td>pr</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            model    scenario variable  count\n",
       "32  EC-Earth3-Veg      ssp126   tasmax      1\n",
       "35  EC-Earth3-Veg      ssp245   tasmax     14\n",
       "34  EC-Earth3-Veg      ssp245       pr     14\n",
       "36  EC-Earth3-Veg      ssp245   tasmin     46\n",
       "0           CESM2  historical       pr     65\n",
       "..            ...         ...      ...    ...\n",
       "9           CESM2      ssp370   tasmin     86\n",
       "10          CESM2      ssp585       pr     86\n",
       "11          CESM2      ssp585   tasmax     86\n",
       "12          CESM2      ssp585   tasmin     86\n",
       "16  CNRM-CM6-1-HR      ssp126       pr     86\n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the grouped dataframe by count low to high\n",
    "grouped_sorted = grouped.sort_values(by='count', ascending=True)\n",
    "grouped_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9340bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models_to_inspect:\n",
    "    df[df[\"model\"] == model].sort_values(by=['scenario', 'variable', 'start_date']).to_csv(f\"{model}_timefix_audit.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1d9efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each model, load the first file encountered in the list \n",
    "datasets = []\n",
    "for model in models_to_inspect:\n",
    "    model_files = [file for file in files if model in file.name]\n",
    "    if model_files:\n",
    "        ds = xr.open_dataset(model_files[0], decode_cf=True, drop_variables=['height', 'spatial_ref', 'type'])\n",
    "        datasets.append((model, ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d5f5825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESM2\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "  * time     (time) object 3kB 2083-01-01 12:00:00 ... 2083-12-31 12:00:00\n",
      "\n",
      "\n",
      "CNRM-CM6-1-HR\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 1966-01-01 12:00:00 ... 1966-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "E3SM-2-0\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 1959-01-01 12:00:00 ... 1959-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "EC-Earth3-Veg\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 2054-01-01 12:00:00 ... 2054-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "GFDL-ESM4\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 2018-01-01 12:00:00 ... 2018-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "HadGEM3-GC31-LL\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 2063-01-01 12:00:00 ... 2063-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "HadGEM3-GC31-MM\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 2015-01-01 12:00:00 ... 2015-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "KACE-1-0-G\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 1967-01-01 12:00:00 ... 1967-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "MIROC6\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 2100-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "MPI-ESM1-2-HR\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 2071-01-01 12:00:00 ... 2071-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "MRI-ESM2-0\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 1995-01-01 12:00:00 ... 1995-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "NorESM2-MM\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 1971-01-01 12:00:00 ... 1971-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n",
      "TaiESM1\n",
      "Coordinates:\n",
      "  * time     (time) object 3kB 2046-01-01 12:00:00 ... 2046-12-31 12:00:00\n",
      "  * lat      (lat) float64 344B 90.0 89.06 88.12 87.17 ... 52.3 51.36 50.42\n",
      "  * lon      (lon) float64 2kB -180.0 -178.8 -177.5 -176.2 ... 176.2 177.5 178.8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset[0])\n",
    "    print(dataset[1].coords)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32364e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snap-geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
